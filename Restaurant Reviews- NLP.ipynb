{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import Imputer\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ndf_train = pd.read_csv(\"../input/uconn_comp_2018_train.csv\")\ndf_test = pd.read_csv(\"../input/uconn_comp_2018_test.csv\")\n\n\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['uconn_comp_2018_test.csv', 'uconn_comp_2018_train.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1480f65dd86b936b0983b8d43ee748b8ed57ae00"
      },
      "cell_type": "code",
      "source": "#data analysis\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "066cd41d87a07556fb453c43a54ec1b96e6972a7"
      },
      "cell_type": "code",
      "source": "columnsRequiredTraining = ['claim_number', 'age_of_driver', 'gender', 'marital_status',\n       'safty_rating', 'annual_income', 'high_education_ind','address_change_ind',\n         'zip_code', 'claim_date',\n       'claim_day_of_week', 'accident_site', 'past_num_of_claims',\n       'witness_present_ind', 'liab_prct', 'channel',\n        'claim_est_payout', 'age_of_vehicle',\n        'vehicle_price', 'vehicle_color', 'vehicle_weight',\n       'fraud']\ncolumnsRequiredTesting = ['claim_number', 'age_of_driver', 'gender', 'marital_status',\n       'safty_rating', 'annual_income', 'high_education_ind','address_change_ind',\n         'zip_code', 'claim_date',\n       'claim_day_of_week', 'accident_site', 'past_num_of_claims',\n       'witness_present_ind', 'liab_prct', 'channel',\n        'claim_est_payout', 'age_of_vehicle',\n        'vehicle_price', 'vehicle_color', 'vehicle_weight']\nTrainingData= df_train[columnsRequiredTraining]\nTestingData= df_test[columnsRequiredTesting]",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "660ae79ac72d1bedea78186de53cce9ad8f2496b"
      },
      "cell_type": "code",
      "source": "#data cleaning\n#values = TrainingData.age_of_vehicle\n#imputer = Imputer()\n#transformed_values = imputer.fit_transform(values)\n\n\nTrainingData[\"age_of_vehicle\"]=TrainingData[\"age_of_vehicle\"].fillna(TrainingData[\"age_of_vehicle\"].mean())\nTrainingData[\"claim_est_payout\"]=TrainingData[\"claim_est_payout\"].fillna(TrainingData[\"claim_est_payout\"].mean())\nTrainingData[\"marital_status\"]=TrainingData[\"marital_status\"].fillna(TrainingData[\"marital_status\"].mean())\nTrainingData[\"witness_present_ind\"]=TrainingData[\"witness_present_ind\"].fillna(TrainingData[\"witness_present_ind\"].mean())\n\nTestingData[\"age_of_vehicle\"]=TestingData[\"age_of_vehicle\"].fillna(TestingData[\"age_of_vehicle\"].mean())\nTestingData[\"claim_est_payout\"]=TestingData[\"claim_est_payout\"].fillna(TestingData[\"claim_est_payout\"].mean())\nTestingData[\"marital_status\"]=TestingData[\"marital_status\"].fillna(TestingData[\"marital_status\"].mean())\nTestingData[\"witness_present_ind\"]=TestingData[\"witness_present_ind\"].fillna(TestingData[\"witness_present_ind\"].mean())\nTestingData.isnull().sum()\n                            ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  import sys\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  if __name__ == '__main__':\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  if sys.path[0] == '':\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  from ipykernel import kernelapp as app\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "claim_number           0\nage_of_driver          0\ngender                 0\nmarital_status         0\nsafty_rating           0\nannual_income          0\nhigh_education_ind     0\naddress_change_ind     0\nzip_code               0\nclaim_date             0\nclaim_day_of_week      0\naccident_site          0\npast_num_of_claims     0\nwitness_present_ind    0\nliab_prct              0\nchannel                0\nclaim_est_payout       0\nage_of_vehicle         0\nvehicle_price          0\nvehicle_color          0\nvehicle_weight         0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train= TrainingData.iloc[:,:-1]\nX_train= X_train.select_dtypes(exclude=['object'])\nX_train\ny_train= TrainingData.iloc[:,-1]\ny_train\nX_test= TestingData.iloc[:,:]\nX_test= X_test.select_dtypes(exclude=['object'])\nX_test\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_x, val_x, train_y, val_y = train_test_split(X_train, y_train,train_size=0.7, \n                                                    test_size=0.3, random_state = 0)\n",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "753de07cf8e76ef512c282ca930f123a10a4807a"
      },
      "cell_type": "code",
      "source": "# Handling missing values\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Imputer\n\n#case 1: Get Model Score from Dropping Columns with Missing Values\n#We've loaded a function score_dataset(X_train, X_test, y_train, y_test) to compare the quality of diffrent approaches to missing values. \n#This function reports the out-of-sample MAE score from a RandomForest.\n\n\ndef score_dataset(train_x, val_x, train_y, val_y):\n    model = RandomForestRegressor()\n    model.fit(train_x, train_y)\n    preds = model.predict(val_x)\n    return mean_absolute_error(val_y, preds)\n\n\n\ncols_with_missing = [col for col in train_x.columns \n                                 if train_x[col].isnull().any()]\nreduced_X_train = train_x.drop(cols_with_missing, axis=1)\nreduced_X_test  = val_x.drop(cols_with_missing, axis=1)\nprint(\"Mean Absolute Error from dropping columns with Missing Values:\")\nprint(score_dataset(reduced_X_train, reduced_X_test, train_y, val_y))\n\n\n#case 2 Get Model Score from Imputation:- \n\n\nmy_imputer = Imputer()\nimputed_X_train = my_imputer.fit_transform(train_x)\nimputed_X_test = my_imputer.transform(val_x)\nprint(\"Mean Absolute Error from Imputation:\")\nprint(score_dataset(imputed_X_train, imputed_X_test, train_y, val_y))\n\n",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mean Absolute Error from dropping columns with Missing Values:\n0.2639444444444445\nMean Absolute Error from Imputation:\n0.26522222222222225\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74fac23c4778d8cdbcb5cee56ef0bf8b9dbda8bc"
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Define model\nmy_model = DecisionTreeRegressor()\n# Fit model\nmy_model.fit(train_x, train_y)\n\n# get predicted prices on validation data\nval_predictions = my_model.predict(val_x)\nprint(mean_absolute_error(val_y, val_predictions))\n\n\nxg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\nxg_reg.fit(train_x,train_y)\nval_predictions = my_model.predict(val_x)\nprint(\"XGBoost:\")\nprint(mean_absolute_error(val_y, val_predictions))\n\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_x, train_y)\nmy_preds = forest_model.predict(val_x)\nprint(\"Random Forest:\")\nprint(mean_absolute_error(val_y, my_preds))\n\n\n#xg_reg.fit(X_train,y_train)\n#preds = xg_reg.predict(X_test)\n#print(preds)\n\n\n  \n\n\n\n##rmse = np.sqrt(mean_squared_error(y_test, preds))\n#print(\"RMSE: %f\" % (rmse))",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-dc822f346546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# get predicted prices on validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "398188cf7d56c6566b8aab7697e6bea2d55e4fa0"
      },
      "cell_type": "code",
      "source": "forest_model = RandomForestRegressor()\nforest_model.fit(train_x, train_y)\nmy_preds = forest_model.predict(val_x)\nprint(mean_absolute_error(val_y, my_preds))",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.2607037037037037\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9711d4071a317a6d909fe5ef5244fe8b6eef957a"
      },
      "cell_type": "code",
      "source": "my_submission = pd.DataFrame({'claim_number':df_test.claim_number , 'fraud': preds})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('sampleSubmission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}